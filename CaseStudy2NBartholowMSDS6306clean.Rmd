---
title: "HR Attrition Predictions"
author: "Nicole Bartholow/CHase Henderson"
date: "12/2/2018"
output: pdf_document
---

```{r Setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(DataExplorer)
library(dplyr)
library(plyr)
library(ggplot2)
library(openintro)
library(reshape2)
library(gridExtra)
library(grid)
library(mlr)
library(caret)
library(e1071)
library(AppliedPredictiveModeling)
library(FSelector)
library(GGally)
```

#Introduction


</p>


####First we bring in the data provided and clean it up for analysis.  
```{r Read Breweries and read Beers files into dataframes}
#set working directory for local computer
#REPRODUCIBLE TIP - CHANGE THIS WORKING DIRECTORY FOR YOUR REPRODUCTION ENVIRONMENT
setwd("/Users/nicolealphin/Desktop/DataScience/MSDS6306-DoingDataScience/HW/CaseStudy2")
DFTrain <- read.csv("./Analysis/Data/CaseStudy2-data.csv", header=TRUE) #import HR Data into DFTrain dataframe
DFVal <- read.csv("./Analysis/Data/CaseStudy2Validation.csv", header=TRUE) #import HR Validation Set into DFVal dataframe
```

#Analysis of missing/unneccesary data
```{r}
EmptyCols <- colSums(is.na(DFTrain))#Check for NA - zero NA fields

#Remove columns that are irrelevant or have only one value
#Feel free to clean this ugliness 
#This was the cleanest way I knew to get rid of several specific columns not next to each other
DFTrainRel <- DFTrain[,-10] #remove Employee Count

DFTrainRel <- DFTrainRel[,-22] #remove Over18 - always Yes
DFTrainRel <- DFTrainRel[,-26] #remove StandardHours - always 80
DFTrainRel <- DFTrainRel[,-34] #remove Rand
DFTrainRel <- DFTrainRel[,-10] #remove Employee Number

#Make test and train the same
DFValRel <- DFVal[,-10] #remove Employee Count
DFValRel <- DFValRel[,-22] #remove Over18
DFValRel <- DFValRel[,-26] #remove StandardHours
DFValRel <- DFValRel[,-34] #remove Rand
DFValRel <- DFValRel[,-10] #remove Employee Number
#DFTrainRel <- within(DFTrainRel, {
#  Gender.Ch <- C(Gender, treatment)
#  print(attributes(Gender.Ch))
#})
#DFTrainRel <- within(DFTrainRel, {
#  OverTime.Ch <- C(OverTime, treatment)
#  print(attributes(OverTime.Ch))
#})

```

```{r Attrition with Income/Rates Graphs}
## The following plots compare Income rates given with Attrition
g1 <- ggplot(DFTrainRel, aes(x = MonthlyIncome, fill = Attrition)) + geom_density(alpha = 0.5) + scale_fill_manual(values = c("#386cb0", "#fdb462"))
g2 <- ggplot(DFTrainRel, aes(x = MonthlyRate, fill = Attrition)) + geom_density(alpha = 0.5) + scale_fill_manual(values = c("#386cb0", "#fdb462"))
g3 <- ggplot(DFTrainRel, aes(x = HourlyRate, fill = Attrition)) + geom_density(alpha = 0.5) + scale_fill_manual(values = c("#386cb0", "#fdb462"))
g4 <- ggplot(DFTrainRel, aes(x = DailyRate, fill = Attrition)) + geom_density(alpha = 0.5) + scale_fill_manual(values = c("#386cb0", "#fdb462"))
OTg <- ggplot(DFTrainRel, aes(x = OTInt, fill = Attrition)) + geom_density(alpha = 0.5) + scale_fill_manual(values = c("#386cb0", "#fdb462"))
## Box Plot of Job Roles compared to OT grouped by Attrition 
DFTrainRel$OTInt <- as.integer(DFTrainRel$OverTime)
OTg2 <- ggplot(DFTrainRel, aes(x = JobRole, y = OTInt, fill = Attrition)) + geom_bar(stat = "identity") + scale_fill_manual(values = c("#386cb0", "#ffa500")) + theme(axis.text.x = element_text(angle = 90, hjust = 1)) + coord_flip()

grid.arrange(g1, g2, g3, g4, OTg, OTg2, ncol = 2, nrow = 3)
```

```{r Attrition More Graphs}
## Total Counts of Attrition Yes VS No
g6 <- ggplot(DFTrainRel, aes(x = Attrition)) + geom_histogram(stat="count", position = "stack", fill = c("#386cb0","#ffa500"))
## Distance from home related to Attrition Density
g1 <- ggplot(DFTrainRel, aes(x = DistanceFromHome, fill = Attrition)) + geom_density(alpha = 0.5) + scale_fill_manual(values = c("#386cb0", "#ffa500"))
## Job Satisfaction related to Attrition Density
g2 <- ggplot(DFTrainRel, aes(x = JobSatisfaction, fill = Attrition)) + geom_density(alpha = 0.5) + scale_fill_manual(values = c("#386cb0", "#ffa500"))
## Percentage of Salary Hike related to Attrition Density
g3 <- ggplot(DFTrainRel, aes(x = PercentSalaryHike, fill = Attrition)) + geom_density(alpha = 0.5) + scale_fill_manual(values = c("#386cb0", "#ffa500"))
## Environment Satisfaction related to Attrition Density
g4 <- ggplot(DFTrainRel, aes(x = EnvironmentSatisfaction, fill = Attrition)) + geom_density(alpha = 0.5) + scale_fill_manual(values = c("#386cb0", "#ffa500"))
## Work Life Balance related to Attrition Density
g7 <- ggplot(DFTrainRel, aes(x = WorkLifeBalance, fill = Attrition)) + geom_density(alpha = 0.5) + scale_fill_manual(values = c("#386cb0", "#ffa500"))
## Years at the company related to Attrition Density
g8 <- ggplot(DFTrainRel, aes(x = YearsAtCompany, fill = Attrition)) + geom_density(alpha = 0.5) + scale_fill_manual(values = c("#386cb0", "#ffa500"))
grid.arrange(g1, g2, g3, g4, g7, g8, ncol = 2, nrow = 3)
## Count of Attrition Stacked by Job Role
g5 <- ggplot(DFTrainRel, aes(x = JobRole, fill = Attrition)) + geom_histogram(stat="count", position = "stack") + scale_fill_manual(values = c("#386cb0", "#ffa500")) + theme(axis.text.x = element_text(angle = 90, hjust = 1))
## Box Plot of Job Roles compared to Monthly Income grouped by Attrition 
ggplot(DFTrainRel, aes(JobRole, MonthlyIncome,  fill = Attrition)) + geom_boxplot(alpha = 0.5) + coord_flip() + scale_fill_manual(values = c("#386cb0", "#ffa500"))
grid.arrange(g5, g6, ncol = 2, nrow = 1)
```

#Boxplots
```{r Plots}
plot_str(CS2Data)
plot_histogram(CS2Data)

#Boxplots of each continuous variable against Attrition
ggplot(data = DFTrainRel, mapping = aes(x = Attrition, y = Age)) +
  geom_boxplot()
ggplot(data = DFTrainRel, mapping = aes(x = Attrition, y = JobSatisfaction)) +
  geom_boxplot() #JobSatisfaction of 1
ggplot(data = DFTrainRel, mapping = aes(x = Attrition, y = DailyRate)) +
  geom_boxplot()
ggplot(data = DFTrainRel, mapping = aes(x = Attrition, y = DistanceFromHome)) +
  geom_boxplot()
ggplot(data = DFTrainRel, mapping = aes(x = Attrition, y = Education)) +
  geom_boxplot()
ggplot(data = DFTrainRel, mapping = aes(x = Attrition, y = EnvironmentSatisfaction)) +
  geom_boxplot()
ggplot(data = DFTrainRel, mapping = aes(x = Attrition, y = Gender)) +
  geom_boxplot() #EnvoronmentSatisfaction=1
ggplot(data = DFTrainRel, mapping = aes(x = Attrition, y = HourlyRate)) +
  geom_boxplot()
ggplot(data = DFTrainRel, mapping = aes(x = Attrition, y = JobInvolvement)) +
  geom_boxplot()
ggplot(data = CS2Data, mapping = aes(x = Attrition, y = JobLevel)) +
  geom_boxplot()#level 1
ggplot(data = DFTrainRel, mapping = aes(x = Attrition, y = MonthlyIncome)) +
  geom_boxplot()
ggplot(data = DFTrainRel, mapping = aes(x = Attrition, y = MonthlyRate)) +
  geom_boxplot()
ggplot(data = DFTrainRel, mapping = aes(x = Attrition, y = NumCompaniesWorked)) +
  geom_boxplot()
ggplot(data = DFTrainRel, mapping = aes(x = Attrition, y = PercentSalaryHike)) +
  geom_boxplot()
ggplot(data = DFTrainRel, mapping = aes(x = Attrition, y = PerformanceRating)) +
  geom_boxplot()
ggplot(data = DFTrainRel, mapping = aes(x = Attrition, y = RelationshipSatisfaction)) +
  geom_boxplot()
ggplot(data = DFTrainRel, mapping = aes(x = Attrition, y = StockOptionLevel)) +
  geom_boxplot()
ggplot(data = DFTrainRel, mapping = aes(x = Attrition, y = TotalWorkingYears)) +
  geom_boxplot()
ggplot(data = DFTrainRel, mapping = aes(x = Attrition, y = TrainingTimesLastYear)) +
  geom_boxplot()
ggplot(data = DFTrainRel, mapping = aes(x = Attrition, y = WorkLifeBalance)) +
  geom_boxplot()
ggplot(data = DFTrainRel, mapping = aes(x = Attrition, y = YearsAtCompany)) +
  geom_boxplot()
ggplot(data = DFTrainRel, mapping = aes(x = Attrition, y = YearsInCurrentRole)) +
  geom_boxplot()
ggplot(data = DFTrainRel, mapping = aes(x = Attrition, y = YearsSinceLastPromotion)) +
  geom_boxplot()
ggplot(data = DFTrainRel, mapping = aes(x = Attrition, y = YearsWithCurrManager)) +
  geom_boxplot()
ggplot(data = DFTrainRel, mapping = aes(x = Attrition, y = OverTime)) +
  geom_boxplot()

DFTrainCorr <- cbind.data.frame(DFTrainRel$Attrition, DFTrainRel$EnvironmentSatisfaction, DFTrainRel$JobInvolvement, DFTrainRel$JobLevel, DFTrainRel$JobRole, DFTrainRel$JobSatisfaction, DFTrainRel$PerformanceRating, DFTrainRel$RelationshipSatisfaction, DFTrainRel$StockOptionLevel, DFTrainRel$WorkLifeBalance)

#not working
#featurePlot(x = DFTrainCorr[, 2:5], y = DFTrainCorr$Attrition, plot = "pairs",
            ## Add a key at the top auto.key = list(columns = 3))

DFTrain %>%
  filter(Attrition == "Yes") %>%
  select_if(is.numeric) %>%
  cor() %>%
  corrplot::corrplot()

DFTrain %>%
  filter(Attrition == "No") %>%
  select_if(is.numeric) %>%
  cor() %>%
  corrplot::corrplot()


```


#Feature Selection Analysis
```{r Feature selection }

DFTrainFS <- cbind.data.frame(DFTrainRel$ID, DFTrainRel$BusinessTravel, DFTrainRel$Department, DFTrainRel$Education, DFTrainRel$EducationField, DFTrainRel$EnvironmentSatisfaction, DFTrainRel$Gender, DFTrainRel$HourlyRate, DFTrainRel$JobInvolvement, DFTrainRel$JobLevel, DFTrainRel$JobRole, DFTrainRel$JobSatisfaction, DFTrainRel$MaritalStatus, DFTrainRel$MonthlyRate, DFTrainRel$NumCompaniesWorked, DFTrainRel$OverTime, DFTrainRel$PercentSalaryHike, DFTrainRel$PerformanceRating, DFTrainRel$RelationshipSatisfaction, DFTrainRel$StockOptionLevel, DFTrainRel$TotalWorkingYears, DFTrainRel$TrainingTimesLastYear, DFTrainRel$WorkLifeBalance, DFTrainRel$YearsAtCompany, DFTrainRel$YearsSinceLastPromotion, DFTrainRel$YearsWithCurrManager, DFTrainRel$YearsInCurrentRole )

DFValFS <- cbind.data.frame(DFValRel$ID, DFValRel$BusinessTravel, DFValRel$Department, DFValRel$Education, DFValRel$EducationField, DFValRel$EnvironmentSatisfaction, DFValRel$Gender, DFValRel$HourlyRate, DFValRel$JobInvolvement, DFValRel$JobLevel, DFValRel$JobRole, DFValRel$JobSatisfaction, DFValRel$MaritalStatus, DFValRel$MonthlyRate, DFValRel$NumCompaniesWorked, DFValRel$OverTime, DFValRel$PercentSalaryHike, DFValRel$PerformanceRating, DFValRel$RelationshipSatisfaction, DFValRel$StockOptionLevel, DFValRel$TotalWorkingYears, DFValRel$TrainingTimesLastYear, DFValRel$WorkLifeBalance, DFValRel$YearsAtCompany, DFValRel$YearsSinceLastPromotion, DFValRel$YearsWithCurrManager, DFValRel$YearsInCurrentRole )

#TrainAttrition <- as.integer(DFTrainRel$Attrition)-1
#TestAttrition <- as.integer(DFValRel$Attrition)-1

TrainAttrition <- DFTrainRel$Attrition
TestAttrition <- DFValRel$Attrition


ctrl <- rfeControl(functions = nbFuncs)

rfe1 <- rfe(x=DFTrainRelFS, y=TrainAttrition, sizes = 2^(2:27), metric = "Accuracy" , rfeControl = ctrl, testx = DFValFS, testy = TestAttrition)
#top5 - DFTrainRel$OverTime, DFTrainRel$TotalWorkingYears, DFTrainRel$YearsAtCompany, DFTrainRel$MaritalStatus, DFTrainRel$YearsInCurrentRole
#Variables Accuracy  Kappa AccuracySD KappaSD Selected
#         4   0.8282 0.1955    0.02308 0.07625         
#         8   0.8326 0.2846    0.02641 0.04974         
#        16   0.8509 0.2403    0.01554 0.06693        *
#        27   0.8498 0.1529    0.01489 0.08675     
        
rfe2 <- rfe(x=DFTrainRelFS, y=TrainAttrition, sizes = 2^(2:27), metric = "Accuracy" , rfeControl = ctrl, testx = DFValFS)
#top5 - DFTrainRel$OverTime, DFTrainRel$TotalWorkingYears, DFTrainRel$YearsAtCompany, DFTrainRel$StockOptionLevel, DFTrainRel$MaritalStatus
#Variables Accuracy  Kappa AccuracySD KappaSD Selected
#         4   0.8339 0.2035    0.01486 0.07075         
#         8   0.8353 0.2942    0.01807 0.06181         
#        16   0.8609 0.2873    0.01107 0.06562        *
#        27   0.8553 0.1725    0.01195 0.06204

rfe3 <- rfe(x=DFTrainRelFS, y=TrainAttrition, sizes = 2^(2:27), metric = "Accuracy" , rfeControl = ctrl)
#top5 - DFTrainRel$OverTime, DFTrainRel$YearsAtCompany, DFTrainRel$YearsInCurrentRole, DFTrainRel$TotalWorkingYears, DFTrainRel$MaritalStatus
#Variables Accuracy  Kappa AccuracySD KappaSD Selected
#         4   0.8310 0.1910    0.02215 0.07589         
#         8   0.8381 0.2837    0.02019 0.06147         
#        16   0.8579 0.2638    0.01753 0.07909        *
#        27   0.8499 0.1517    0.01690 0.06859     




```



```{r Naive Bayes}
Naive_Bayes_Model <- naiveBayes(Attrition ~ ., data = DFTrainRel)

Naive_Bayes_Model

NB_Prediction <- predict(Naive_Bayes_Model, DFTrainRel)

table(NB_Prediction,DFTrainRel$Attrition)

test_data <- read.csv('Desktop/NB_NB/CaseStudy2Validation.csv')

NB_Test <- predict(Naive_Bayes_Model, DFValRel)

confusionMatrix(table(NB_Test,DFValRel$Attrition))

```


#Set Survey Integers as Factors to run auto NB function
#Create New Dataset to Play with
```{r} DFTrainRelFacs <- DFTrainRel
DFTrainRelFacs$Education <- as.factor(DFTrainRelFacs$Education)
DFTrainRelFacs$EnvironmentSatisfaction <- as.factor(DFTrainRelFacs$EnvironmentSatisfaction)
DFTrainRelFacs$JobInvolvement <- as.factor(DFTrainRelFacs$JobInvolvement)
DFTrainRelFacs$JobLevel <- as.factor(DFTrainRelFacs$JobLevel)
DFTrainRelFacs$JobSatisfaction <- as.factor(DFTrainRelFacs$JobSatisfaction)
DFTrainRelFacs$NumCompaniesWorked <- as.factor(DFTrainRelFacs$NumCompaniesWorked)
DFTrainRelFacs$PerformanceRating <- as.factor(DFTrainRelFacs$PerformanceRating)
DFTrainRelFacs$RelationshipSatisfaction <- as.factor(DFTrainRelFacs$RelationshipSatisfaction)
DFTrainRelFacs$StockOptionLevel <- as.factor(DFTrainRelFacs$StockOptionLevel)
DFTrainRelFacs$TrainingTimesLastYear <- as.factor(DFTrainRelFacs$TrainingTimesLastYear)
DFTrainRelFacs$WorkLifeBalance <- as.factor(DFTrainRelFacs$WorkLifeBalance)



#Fitting the Naive Bayes model
Naive_Bayes_Model=naiveBayes(Attrition ~., data=DFTrainRelFacs)
#What does the model say? Print the model summary
Naive_Bayes_Model


DFTrainRelFacs$AttInt <- as.integer(DFTrainRelFacs$Attrition)
DFTrainRelFacs$AttInt2 <- c(1)
DFTrainRelFacs$AttInt <- DFTrainRelFacs$AttInt - DFTrainRelFacs$AttInt2
model1 <- glm(formula = AttInt ~ ., family = binomial(link = "logit"), data = DFTrainRelFacs)
summary(model1)

```



```{r Naive Bayes Percentage Analysis}
#Percentage Analysis
AttrY <- DFTrainRel[grep("Yes", DFTrainRel$Attrition), ]
AttrN <- DFTrainRel[grep("No", DFTrainRel$Attrition), ]
pAttrY <- dim(AttrY)[1] / (dim(AttrY)[1] + dim(AttrN)[1])
pAttrN <- 1 - pAttrY

#OverTime
pOTYGivenAttY <- length(grep("Yes",AttrY$OverTime))/dim(AttrY)[1]
pOTYGivenAttN <- length(grep("Yes",AttrN$OverTime))/dim(AttrN)[1]

#Environment Satisfaction
pES1GivenAttY <- length(grep(1,AttrY$EnvironmentSatisfaction))/dim(AttrY)[1]
pES1GivenAttN <- length(grep(1,AttrN$EnvironmentSatisfaction))/dim(AttrN)[1]
pES2GivenAttY <- length(grep(2,AttrY$EnvironmentSatisfaction))/dim(AttrY)[1]
pES2GivenAttN <- length(grep(2,AttrN$EnvironmentSatisfaction))/dim(AttrN)[1]
pES3GivenAttY <- length(grep(3,AttrY$EnvironmentSatisfaction))/dim(AttrY)[1]
pES3GivenAttN <- length(grep(3,AttrN$EnvironmentSatisfaction))/dim(AttrN)[1]
pES4GivenAttY <- length(grep(4,AttrY$EnvironmentSatisfaction))/dim(AttrY)[1]
pES4GivenAttN <- length(grep(4,AttrN$EnvironmentSatisfaction))/dim(AttrN)[1]
```




```{r kNN models}
#kNN for Attrition

#k = 34 (Square root of number of observations in training set) Overall Accuracy .8367 
#Sets everything to NO
results34 <- class::knn(DFTrainRel[,c(10, 20, 33)], DFValRel[,c(10, 20, 33)], DFTrainRel$Att, k=34)
DFValRel$AttPred34 <- results34
confusionMatrix(table(DFValRel$Attrition,DFValRel$AttPred34))

#k = 1 Overall Accuracy 0.73333
#The only kNN where I predicted some of the positives
results1 <- class::knn(DFTrainRel[,c(10, 20, 33)], DFValRel[,c(10, 20, 33)], DFTrainRel$Att, k=1)
DFValRel$AttPred1 <- results1
confusionMatrix(table(DFValRel$Attrition,DFValRel$AttPred1))

#k = 2 Overall Accuracy 0.6767
#The only kNN where I predicted some of the positives
results2 <- class::knn(DFTrainRel[,c(10, 20, 33)], DFValRel[,c(10, 20, 33)], DFTrainRel$Att, k=2)
DFValRel$AttPred2 <- results2
confusionMatrix(table(DFValRel$Attrition,DFValRel$AttPred2))

#k = 3 Overall Accuracy 0.6767
#The only kNN where I predicted some of the positives correctly
results3 <- class::knn(DFTrainRel[,c(10, 20, 33)], DFValRel[,c(10, 20, 33)], DFTrainRel$Att, k=3)
DFValRel$AttPred3 <- results3
confusionMatrix(table(DFValRel$Attrition,DFValRel$AttPred3))

#k = 5 Overall Accuracy 0.83
results5 <- class::knn(DFTrainRel[,c(10, 20, 33)], DFValRel[,c(10, 20, 33)], DFTrainRel$Att, k=5)
DFValRel$AttPred5 <- results5
confusionMatrix(table(DFValRel$Attrition,DFValRel$AttPred5))

#k = 10 Overall Accuracy 0.8267
results10 <- class::knn(DFTrainRel[,c(10, 20, 33)], DFValRel[,c(10, 20, 33)], DFTrainRel$Att, k=10)
DFValRel$AttPred10 <- results10
confusionMatrix(table(DFValRel$Attrition,DFValRel$AttPred10))

#k = 20 Overall Accuracy .8367
results20 <- class::knn(DFTrainRel[,c(10, 20, 33)], DFValRel[,c(10, 20, 33)], DFTrainRel$Att, k=20)
DFValRel$AttPred20 <- results20
confusionMatrix(table(DFValRel$Attrition,DFValRel$AttPred20))


#k = 30 0Overall Accuracy Overall Accuracy .8367
results30 <- class::knn(DFTrainRel[,c(10, 20, 33)], DFValRel[,c(10, 20, 33)], DFTrainRel$Att, k=30)
DFValRel$AttPred30 <- results30
confusionMatrix(table(DFValRel$Attrition,DFValRel$AttPred30))


#Try with additional variables - does not improve accuracy over .8367
#k = 3Plus (Square root of number of observations in training set) Overall Accuracy .8367
results3Plus <- class::knn(DFTrainRel[,c(10, 13,  20, 33)], DFValRel[,c(10, 13, 20, 33)], DFTrainRel$Att, k=3)
DFValRel$AttPred3Plus <- results3Plus
confusionMatrix(table(DFValRel$Attrition,DFValRel$AttPred3Plus))

#k = 1 Overall Accuracy 
#Try different variables - remove overtime worked .7433
results1 <- class::knn(DFTrainRel[,c(10, 33)], DFValRel[,c(10,  33)], DFTrainRel$Att, k=1)
DFValRel$AttPred1 <- results1
confusionMatrix(table(DFValRel$Attrition,DFValRel$AttPred1))

#k = 1 Overall Accuracy 
#Try different variables - add Job Involvement .74
#Correctly predicted 7 yes
results1 <- class::knn(DFTrainRel[,c(10, 13, 33)], DFValRel[,c(10, 13,  33)], DFTrainRel$Att, k=1)
DFValRel$AttPred1 <- results1
confusionMatrix(table(DFValRel$Attrition,DFValRel$AttPred1))

#k = 3 Overall Accuracy 
#Try different variables - add Job Involvement, increase k .83
#Correctly predicted 1 yes
results1 <- class::knn(DFTrainRel[,c(11, 14, 33)], DFValRel[,c(11, 14,  33)], DFTrainRel$Att, k=3)
DFValRel$AttPred1 <- results1
confusionMatrix(table(DFValRel$Attrition,DFValRel$AttPred1))

#k = 3 Overall Accuracy 
#Try different variables Envoironment Satisfaction, Hourly Rate, Years with Current Manager.8067
#Correctly predict 4 yes
results1 <- class::knn(DFTrain[,c(11, 13, 33)], DFVal[,c(11, 13,  33)], DFTrain$Att, k=3)
DFValRel$AttPred1 <- results1
confusionMatrix(table(DFValRel$Attrition,DFValRel$AttPred1))
```


#Making Categorical Variables into Continuous Variables
```{r}
#Assign Factors to Survey Responses
Departments <- c(1, 2, 3)
EducationFields <- c(1, 2, 3, 4, 5, 6)
JobRole <- c(1, 2, 3, 4, 5, 6, 7, 8, 9)

ActualDept <- c("Human Resources","Research & Development", "Sales")
ActualEd <- c("Human Resources","Life Sciences", "Marketing", "Medical", "Other", "Technical Degree")
ActualRole <- c("Healthcare Representative", "Human Resources","Laboratory Technician", "Manager", "Manufacturing Director", "Research Director", "Research Scientist", "Sales Executive", "Sales Representative")
DFTrainRel$DeptInt = factor(DFTrainRel$DeptInt, levels=Styles, labels = StylesF) 

#k = 3 Overall Accuracy 
#Try different variables Envoironment Satisfaction, Hourly Rate, Years with Current Manager.8067
#Correctly predict 4 yes
TrainDF<- DFTrainRel
ValDF <- DFValRel

results1 <- class::knn(data.frame(DFTrainRel[,c(33)]), data.frame(DFValRel[,c(33)]), DFTrainRel$Att, k=1)
DFValRel$AttPred1 <- results1
confusionMatrix(table(DFValRel$Attrition,DFValRel$AttPred1))
```


```{r Cross Validation model}
resultsCV <- class::knn.cv(DFTrainRel[,c(10, 20, 33)],DFTrainRel$Att, k=1)
DFTrainRel$AttPredCV <- resultsCV
confusionMatrix(table(DFTrainRel$Attrition,DFTrainRel$AttPredCV))
```

```{r}
##Logistic Regression for Feature Selection
#Turn Factors into integers 
CS2DataRelevant$OTInt <- as.integer(CS2DataRelevant$OverTime)
CS2DataRelevant$AttInt <- as.integer(CS2DataRelevant$Attrition)
CS2ValRel$OTInt <- as.integer(CS2Val$OverTime)
CS2Val$AttInt <- as.integer(CS2Val$Attrition)

CS2LRModel <- data.frame(cbind(CS2DataRelevant$ID, CS2DataRelevant$Attrition, CS2DataRelevant$AttInt, CS2DataRelevant$OverTime, CS2DataRelevant$EnvironmentSatisfaction, CS2DataRelevant$NumCompaniesWorked, CS2DataRelevant$JobInvolvement, CS2DataRelevant$BusinessTravel, CS2DataRelevant$YearsSinceLastPromotion, CS2DataRelevant$JobSatisfaction))
CS2LRModel$AttInt2 <- c(1)
CS2LRModel$AttInt <- CS2LRModel$AttInt - CS2LRModel$AttInt2

colnames(CS2LRModel) <- c('ID', 'Attrition', 'AttInt', 'OverTime', 'EnvironmentSatisfaction', 'NumCompaniesWorked', 'JobInvolvement', 'BusinessTravel', 'YearsSinceLastPromotion', 'JobSatisfaction')



model <- glm(formula = AttInt ~ ., family = binomial(link = "logit"), data = CS2LRModel)
summary(model)
model <- glm(formula = Attrition ~  OverTime+EnvironmentSatisfaction + NumCompaniesWorked + JobInvolvement + BusinessTravel + YearsSinceLastPromotion + JobSatisfaction, family = binomial(link = "logit"), data = CS2LRModel)
summary(model)

CS2LRModel <- CS2LRModel[,-7] #remove 'YearsSinceLastPromotion', 'JobSatisfaction'
CS2LRModel <- CS2LRModel[,-7] #remove 'YearsSinceLastPromotion', 'JobSatisfaction'

model <- glm(formula = Attrition ~  OverTime+EnvironmentSatisfaction + NumCompaniesWorked + JobInvolvement , family = binomial(link = "logit"), data = CS2LRModel)
summary(model)


```


###Recommendations Summary
####To recap the opportunities, 



#### Other References 
###Youtube PowerPoint Presentation
#### https://youtu.be/X7wWLbDmeDM
###Github Respository
####https://github.com/NicoleABartholow/MSDS6306CaseStudy2



